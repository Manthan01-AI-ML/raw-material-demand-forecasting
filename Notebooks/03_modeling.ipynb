{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c1ea05-b6ed-48a6-97ae-4234b743bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65f094d-8d2d-4d42-981e-30148cf37bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d72143f-2ac5-4eb1-a9fb-c901f87bd548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (clean) shape: (2193, 9)\n",
      "Feature (ML) shape: (2103, 19)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Load datasets (base for SARIMA, features for ML)\n",
    "# -------------------------------\n",
    "df_base = pd.read_csv(\"../data/processed/cleaned_data.csv\")       # has Material_Name\n",
    "df_feat = pd.read_csv(\"../data/processed/feature_data.csv\")       # one-hot features\n",
    "df_base[\"Date\"] = pd.to_datetime(df_base[\"Date\"])\n",
    "df_feat[\"Date\"] = pd.to_datetime(df_feat[\"Date\"])\n",
    "\n",
    "print(\"Base (clean) shape:\", df_base.shape)\n",
    "print(\"Feature (ML) shape:\", df_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6e2f9d-d21b-4b67-b50c-bd342a6465ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test shapes -> base: (1641, 9) (552, 9) | feat: (1551, 19) (552, 19)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Time-based split (align both)\n",
    "# -------------------------------\n",
    "split_date = pd.Timestamp(\"2024-07-01\")\n",
    "\n",
    "base_train = df_base[df_base[\"Date\"] < split_date].copy()\n",
    "base_test  = df_base[df_base[\"Date\"] >= split_date].copy()\n",
    "\n",
    "feat_train = df_feat[df_feat[\"Date\"] < split_date].copy()\n",
    "feat_test  = df_feat[df_feat[\"Date\"] >= split_date].copy()\n",
    "\n",
    "target = \"Quantity_Consumed\"\n",
    "feature_cols = [c for c in df_feat.columns if c not in [\"Date\", target]]\n",
    "\n",
    "print(\"Train/Test shapes -> base:\", base_train.shape, base_test.shape, \"| feat:\", feat_train.shape, feat_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82da83d7-fe57-47e0-930e-637e7f0e6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA done for TMT_Steel (n_test=184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA done for Cement (n_test=184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA done for Sand (n_test=184)\n",
      "SARIMA predictions shape: (552, 4)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1) SARIMA per material (using base data with Material_Name)\n",
    "# -------------------------------\n",
    "sarima_preds_list = []\n",
    "for mat in base_train[\"Material_Name\"].unique():\n",
    "    mt_train = base_train[base_train[\"Material_Name\"] == mat].sort_values(\"Date\").set_index(\"Date\")\n",
    "    mt_test  = base_test [base_test [\"Material_Name\"] == mat].sort_values(\"Date\").set_index(\"Date\")\n",
    "\n",
    "    # Defensive: need non-empty series\n",
    "    if len(mt_train) == 0 or len(mt_test) == 0:\n",
    "        print(f\"Skip SARIMA for {mat} due to insufficient data.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Lightweight seasonal model to keep it fast on i3/8GB\n",
    "        model = SARIMAX(mt_train[target], order=(1,1,1), seasonal_order=(1,1,1,12), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res = model.fit(disp=False)\n",
    "        preds = res.forecast(steps=len(mt_test))\n",
    "        tmp = mt_test[[target]].copy()\n",
    "        tmp[\"Material_Name\"] = mat\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp.rename(columns={target: \"y_true\"}, inplace=True)\n",
    "        tmp[\"SARIMA_Pred\"] = preds.values\n",
    "        sarima_preds_list.append(tmp[[\"Date\", \"Material_Name\", \"y_true\", \"SARIMA_Pred\"]])\n",
    "        print(f\"SARIMA done for {mat} (n_test={len(mt_test)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ SARIMA failed for {mat}: {e}\")\n",
    "\n",
    "sarima_df = pd.concat(sarima_preds_list, ignore_index=True) if sarima_preds_list else pd.DataFrame()\n",
    "print(\"SARIMA predictions shape:\", sarima_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f4da11-6df7-446e-88ff-848e40e40726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2) ML models (RF + XGBoost) on feature data\n",
    "# -------------------------------\n",
    "X_tr, y_tr = feat_train[feature_cols], feat_train[target]\n",
    "X_te, y_te = feat_test [feature_cols], feat_test [target]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=160, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "rf_preds = rf.predict(X_te)\n",
    "\n",
    "xg = xgb.XGBRegressor(\n",
    "    n_estimators=240, learning_rate=0.05, max_depth=5,\n",
    "    subsample=0.8, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
    ")\n",
    "xg.fit(X_tr, y_tr)\n",
    "xg_preds = xg.predict(X_te)\n",
    "\n",
    "# Simple hybrid of RF + XGB\n",
    "hyb_preds = (rf_preds + xg_preds) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be6f57b-4ad5-4dc1-b1de-cd277faaaef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ML Evaluation on test period ===\n",
      "RandomForest | RMSE:    5.686 | MAPE:   4.02%\n",
      "XGBoost      | RMSE:    5.638 | MAPE:   4.01%\n",
      "Hybrid(RF+XGB) | RMSE:    5.589 | MAPE:   3.99%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 3) Evaluation helpers\n",
    "# -------------------------------\n",
    "def eval_metrics(y_true, y_pred, label):\n",
    "    mse = mean_squared_error(y_true, y_pred)   # no 'squared' kwarg\n",
    "    rmse = np.sqrt(mse)                        # turn MSE -> RMSE\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f\"{label:12s} | RMSE: {rmse:8.3f} | MAPE: {mape*100:6.2f}%\")\n",
    "    return rmse, mape\n",
    "\n",
    "print(\"\\n=== ML Evaluation on test period ===\")\n",
    "rf_scores  = eval_metrics(y_te, rf_preds, \"RandomForest\")\n",
    "xgb_scores = eval_metrics(y_te, xg_preds, \"XGBoost\")\n",
    "hyb_scores = eval_metrics(y_te, hyb_preds, \"Hybrid(RF+XGB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fab510d-bd6d-429b-a0a1-65c6dd3ac862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARIMA       | RMSE:   26.219 | MAPE:  21.47%\n"
     ]
    }
   ],
   "source": [
    "# SARIMA eval (merge by Date+Material_Name to align truth)\n",
    "if not sarima_df.empty:\n",
    "    # Build ground truth frame keyed by Date+Material_Name from base_test\n",
    "    truth = base_test[[\"Date\", \"Material_Name\", target]].copy()\n",
    "    truth.rename(columns={target: \"y_true\"}, inplace=True)\n",
    "    sarima_eval = sarima_df.merge(truth, on=[\"Date\", \"Material_Name\", \"y_true\"], how=\"inner\")\n",
    "    s_rmse, s_mape = eval_metrics(sarima_eval[\"y_true\"], sarima_eval[\"SARIMA_Pred\"], \"SARIMA\")\n",
    "else:\n",
    "    print(\"No SARIMA predictions available for evaluation.\")\n",
    "    s_rmse, s_mape = (np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42af4b89-3838-4d36-b0ad-367e3fadd57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models saved to ../models/\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4) Save models\n",
    "# -------------------------------\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(rf, \"../models/rf_model.pkl\")\n",
    "joblib.dump(xg, \"../models/xgb_model.pkl\")\n",
    "print(\"✅ Models saved to ../models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c378df9-c464-43fa-b216-0c47cf686ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved test predictions to data/processed/ for Step 6.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 6) Save test-set predictions for evaluation notebook (Step 6)\n",
    "# -------------------------------\n",
    "\n",
    "# Build tidy predictions DataFrame for ML models\n",
    "ml_preds_df = pd.DataFrame({\n",
    "    \"Date\": feat_test[\"Date\"].reset_index(drop=True),\n",
    "    \"y_true\": y_te.reset_index(drop=True),\n",
    "    \"RF_Pred\": rf_preds,\n",
    "    \"XGB_Pred\": xg_preds,\n",
    "    \"HYB_Pred\": (rf_preds + xg_preds) / 2\n",
    "})\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "ml_preds_df.to_csv(\"../data/processed/test_predictions_ml.csv\", index=False)\n",
    "\n",
    "# Also persist SARIMA predictions if available\n",
    "if not sarima_df.empty:\n",
    "    sarima_df.to_csv(\"../data/processed/test_predictions_sarima.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved test predictions to data/processed/ for Step 6.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0a9da-46d9-4065-9b8c-24ea033622a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
